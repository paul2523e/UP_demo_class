{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "# A polinomial fit is evidently not a good model, but it is used because of its mathematical simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918acf70c8e24d9f8f86c305a5547282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='Model Complexity', layout=Layout(width='600px'), max=10,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_polynomial_fit(degree, test_visible)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from ipywidgets import interact,ToggleButton,IntSlider,Layout,VBox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MAX_DEGREE = 10\n",
    "NOISE_LEVEL = 0.2\n",
    "N_POINTS = 30\n",
    "TEST_SIZE = 0.4\n",
    "\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "def plot_polynomial_fit(degree,test_visible):\n",
    "    # reproducibility:\n",
    "    \n",
    "    np.random.seed(SEED)\n",
    "    #domain:\n",
    "    min_x,max_x = -1,1\n",
    "    x = np.linspace(min_x, max_x, N_POINTS)\n",
    "    # real function:\n",
    "    def fun(x):\n",
    "        return  0.5*x**3 + np.cos(2*x) +np.random.normal(0, NOISE_LEVEL, x.shape)\n",
    "    \n",
    "    y = fun(x)\n",
    "    # train test splitting and output evaluation for synthetic data:\n",
    "    # to avoid extrapolation, make sure first and last points are in train:\n",
    "    # this is just to focus around the point intended in the class:\n",
    "    indices = range(N_POINTS)\n",
    "    \n",
    "    # Split using indices\n",
    "    train_idx, test_idx = train_test_split(indices, test_size=TEST_SIZE, random_state=SEED)\n",
    "    train_idx += [0,N_POINTS-1]\n",
    "    train_idx = list(set(train_idx))\n",
    "    test_idx = [v for v in test_idx if v not in train_idx]\n",
    "    # Use the indices to get the train and test sets\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    #x_train,x_test,y_train,y_test =  train_test_split(x,y,test_size=TEST_SIZE, random_state=SEED,)\n",
    "    \n",
    "    # fits mapping:\n",
    "    fits_dict = {}\n",
    "    train_MSE_dict = {}\n",
    "    test_MSE_dict = {}\n",
    "    colors = []\n",
    "    # build fits:\n",
    "    degree_range = (1, MAX_DEGREE, 1) #start,end and step\n",
    "\n",
    "    # Create plot\n",
    "    # Create a figure with 1 row and 2 columns\n",
    "    fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "    # Define grid spec: first subplot will take more space (e.g. 2/3 of the width)\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1])  # The first subplot is twice as wide as the second\n",
    "\n",
    "    # Create subplots with the custom grid spec\n",
    "    axs = [plt.subplot(g) for g in gs]\n",
    "\n",
    "    # iteract of ipywidgets includes last element but range doesnt\n",
    "    # which casues with range below to be a little ugly:\n",
    "    for deg in range(degree_range[0],degree_range[1]+1,degree_range[2]):   \n",
    "\n",
    "        # Fit polynomial\n",
    "        coeffs,residuals, _, _, _  = np.polyfit(x_train, y_train, deg,full=True,rcond=np.finfo(float).eps/10)\n",
    "        \n",
    "        poly_func= np.poly1d(coeffs)\n",
    "        #append new fit:\n",
    "        fits_dict[deg] = poly_func\n",
    "        #per numpy: residuals – sum of squared residuals of the least squares fit\n",
    "        #residuals provided before as sum of squared values:\n",
    "        train_MSE_dict[deg] = np.sqrt(residuals)/len(x_train)\n",
    "\n",
    "        #the outputs calculated using the \"trained\" model\n",
    "        y_pred_train = poly_func(x_train)\n",
    "        y_pred_test = poly_func(x_test)\n",
    "        # the error between the real values for x_test, time N to make it sum\n",
    "        #as in redisuals\n",
    "        test_MSE_dict[deg] = mean_squared_error(y_true=y_test,y_pred=y_pred_test)\n",
    "        \n",
    "        if deg == degree:\n",
    "            colors.append('red')\n",
    "            #plot the given left side chart\n",
    "            #axs[0].scatter(x_train, y_train, label='Noisy Data')\n",
    "            axs[0].plot(x_train, y_train, 'x', color='black', markersize = 16, label='Train Data - Real')\n",
    "            axs[0].plot(x_train, y_pred_train, 'o', color='gray', label='Train Data - Predicted')\n",
    "            if test_visible:\n",
    "                axs[0].plot(x_test, y_test, 'x', color='lightgreen', label='Data point (test)')\n",
    "                axs[0].plot(x_test, y_pred_test, 'o', color='green', label='Predicted by model (test)')\n",
    "            # plot the actual model including point inbeweeen:\n",
    "            x1 = np.linspace(min_x, max_x, 5*N_POINTS)\n",
    "            axs[0].plot(x1, poly_func(x1),'k--', label=f'Model fit')\n",
    "\n",
    "            axs[0].set_title(f' A fit of some data points with some simplistic model')\n",
    "            axs[0].set_xlabel('x : The data we have as predictor(s)')\n",
    "            axs[0].set_ylabel('y : The Value we attempt to predict')\n",
    "\n",
    "\n",
    "        else:\n",
    "            colors.append('black')\n",
    "    # there are better ways of doing this, but this is simpler to explain:\n",
    "    y_min = min(min(y),min(y_pred_test),min(y_pred_train))\n",
    "    y_max = max(max(y),max(y_pred_test),max(y_pred_train))\n",
    "    axs[0].set_ylim(1.1*y_min,1.1*y_max)\n",
    "\n",
    "    #plot the accuracies\n",
    "    axs[1].scatter(train_MSE_dict.keys(), train_MSE_dict.values(), color = colors, label='Error (entrenamiento)')\n",
    "    axs[1].plot(train_MSE_dict.keys(), train_MSE_dict.values(),\"k--\")\n",
    "    if test_visible:\n",
    "        axs[1].scatter(test_MSE_dict.keys(), test_MSE_dict.values(), color = [c if c == 'red' else 'green' for c in colors], label='Error (test)')\n",
    "        axs[1].plot(test_MSE_dict.keys(), test_MSE_dict.values(),\"g--\")\n",
    "    axs[1].axvline(x=degree, color='red', linestyle='--', label='error')\n",
    "    axs[1].set_xlabel('<-- lower -- Model Complexity  -- higher-->')\n",
    "    axs[1].set_ylabel('Mean Squared Error')\n",
    "    axs[1].set_yscale(\"log\")\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    axs[0].legend(loc='upper left',)\n",
    "\n",
    "    #accuracy_score()\n",
    "\n",
    "    #fig.show()\n",
    "\n",
    "# Create interaction\n",
    "interact(plot_polynomial_fit, \n",
    "         degree=IntSlider(description='Model Complexity', \n",
    "                          min=1, \n",
    "                          max=MAX_DEGREE, \n",
    "                          step=1, \n",
    "                          value=5, \n",
    "                          layout=Layout(width='600px'),  # Set the overall width\n",
    "                          style={'description_width (polinomial degree)': '400px'},  # Increase the description width\n",
    "                          height='60px'),\n",
    "         test_visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets.embed import embed_minimal_html\n",
    "# embed_minimal_html('export.html', views=[plot_polynomial_fit], title='Widgets export')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### What happens if i try to use that model with high variance for prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
